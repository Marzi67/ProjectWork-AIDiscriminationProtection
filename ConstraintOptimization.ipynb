{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a76b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Uni\\ThirdTerm\\ProjectWork\\PythonCode\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../../fair_classification/') # the code for fair classification is in this directory\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from scipy.optimize import minimize # for loss func minimization\n",
    "from collections import defaultdict\n",
    "from random import seed, shuffle\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9bffb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import urllib.request\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import preprocessing\n",
    "from random import seed, shuffle\n",
    "\n",
    "sys.path.insert(0, '../../fair_classification/') # the code for fair classification is in this directory\n",
    "import Utils as ut\n",
    "\n",
    "SEED = 1234\n",
    "seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\"\"\"\n",
    "    The adult dataset can be obtained from: https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\n",
    "    The code will look for the data file in the present directory, if it is not found, it will download them from GitHub.\n",
    "\"\"\"\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14777289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compas_data():\n",
    "\n",
    "\tFEATURES_CLASSIFICATION = [\"age_cat\", \"priors_count\", \"c_charge_degree\"] #features to be used for classification\n",
    "\tCONT_VARIABLES = [\"priors_count\"] # continuous features, will need to be handled separately from categorical features, categorical features will be encoded using one-hot\n",
    "\tCLASS_FEATURE = \"two_year_recid\" # the decision variable\n",
    "\tSENSITIVE_ATTRS = [\"sex\",\"race\"] \n",
    "\n",
    "\n",
    "\tCOMPAS_INPUT_FILE = \"compas-scores-two-years.csv\"\n",
    "\n",
    "\t# load the data and get some stats\n",
    "\tdf = pd.read_csv(COMPAS_INPUT_FILE)\n",
    "\tdf = df.dropna(subset=[\"days_b_screening_arrest\"]) # dropping missing vals\n",
    "\t\n",
    "\t# convert to np array\n",
    "\tdata = df.to_dict('list')\n",
    "\tfor k in data.keys():\n",
    "\t\tdata[k] = np.array(data[k])\n",
    "\n",
    "\n",
    "\t\"\"\" Filtering the data \"\"\"\n",
    "\n",
    "\t# These filters are the same as propublica (refer to https://github.com/propublica/compas-analysis)\n",
    "\t# If the charge date of a defendants Compas scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense. \n",
    "\tidx = np.logical_and(data[\"days_b_screening_arrest\"]<=30, data[\"days_b_screening_arrest\"]>=-30)\n",
    "\n",
    "\n",
    "\t# We coded the recidivist flag -- is_recid -- to be -1 if we could not find a compas case at all.\n",
    "\tidx = np.logical_and(idx, data[\"is_recid\"] != -1)\n",
    "\n",
    "\t# In a similar vein, ordinary traffic offenses -- those with a c_charge_degree of 'O' -- will not result in Jail time are removed (only two of them).\n",
    "\tidx = np.logical_and(idx, data[\"c_charge_degree\"] != \"O\") # F: felony, M: misconduct\n",
    "\n",
    "\t# We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility.\n",
    "\tidx = np.logical_and(idx, data[\"score_text\"] != \"NA\")\n",
    "\n",
    "\t# we will only consider blacks and whites for this analysis\n",
    "\tidx = np.logical_and(idx, np.logical_or(data[\"race\"] == \"African-American\", data[\"race\"] == \"Caucasian\"))\n",
    "\t# select the examples that satisfy this criteria\n",
    "\tfor k in data.keys():\n",
    "\t\tdata[k] = data[k][idx]\n",
    "\n",
    "\n",
    "\t\"\"\" Feature normalization and one hot encoding \"\"\"\n",
    "\n",
    "\t# convert class label 0 to -1\n",
    "\ty = data[CLASS_FEATURE]\n",
    "\ty[y==0] = -1\n",
    "\n",
    "\t\n",
    "\t\n",
    "\tprint (\"\\nNumber of people recidivating within two years\")\n",
    "\tprint (pd.Series(y).value_counts())\n",
    "\tprint (\"\\n\")\n",
    "\n",
    "\n",
    "\tX = np.array([]).reshape(len(y), 0) # empty array with num rows same as num examples, will hstack the features to it\n",
    "\tx_control = defaultdict(list)\n",
    "\tfeature_names = []\n",
    "\tfor attr in FEATURES_CLASSIFICATION:\n",
    "\t\tvals = data[attr]\n",
    "\t\tif attr in CONT_VARIABLES:\n",
    "\t\t\tvals = [float(v) for v in vals]\n",
    "\t\t\tvals = preprocessing.scale(vals) # 0 mean and 1 variance  \n",
    "\t\t\tvals = np.reshape(vals, (len(y), -1)) # convert from 1-d arr to a 2-d arr with one col\n",
    "\n",
    "\t\telse: # for binary categorical variables, the label binarizer uses just one var instead of two\n",
    "\t\t\tlb = preprocessing.LabelBinarizer()\n",
    "\t\t\tlb.fit(vals)\n",
    "\t\t\tvals = lb.transform(vals)\n",
    "\n",
    "\t\t# add to sensitive features dict\n",
    "\t\t#if attr in SENSITIVE_ATTRS:\n",
    "\t\t\t#x_control[attr] = vals\n",
    "\t\t#print(\"x_control\",x_control)\n",
    "\n",
    "\t\t# add to learnable features\n",
    "\t\tX = np.hstack((X, vals))\n",
    "\n",
    "\t\tif attr in CONT_VARIABLES: # continuous feature, just append the name\n",
    "\t\t\tfeature_names.append(attr)\n",
    "\t\telse: # categorical features\n",
    "\t\t\tif vals.shape[1] == 1: # binary features that passed through lib binarizer\n",
    "\t\t\t\tfeature_names.append(attr)\n",
    "\t\t\telse:\n",
    "\t\t\t\tfor k in lb.classes_: # non-binary categorical features, need to add the names for each cat\n",
    "\t\t\t\t\tfeature_names.append(attr + \"_\" + str(k))\n",
    "\t\t# add to sensitive features dict\n",
    "\tfor attr in SENSITIVE_ATTRS:\n",
    "\t\tx_control[attr] = data[attr]\n",
    "\t#print(\"x_control0\",x_control)                    \n",
    "\t# convert the sensitive feature to 1-d array\n",
    "\tx_control = dict(x_control)\n",
    "\t#print (\"x_control\",x_control)\n",
    "\tbinary_encoded_data = {}   \n",
    "\t# Iterate through the keys (sensitive attributes) in the x_control dictionary\n",
    "\tfor attr in x_control:\n",
    "\t\t# Perform binary encoding for each attribute separately\n",
    "\n",
    "\t\t# For 'race' attribute:\n",
    "\t\tif attr == 'race':\n",
    "\t\t\t# Convert the value of the 'race' attribute to a NumPy array if it is not already\n",
    "\t\t\trace_array = np.array(x_control[attr])\n",
    "\t\t\trace_binary = (race_array == 'Caucasian').astype(int)\n",
    "\t\t\tbinary_encoded_data[attr] = race_binary\n",
    "\n",
    "\t\t# For 'sex' attribute:\n",
    "\t\telif attr == 'sex':\n",
    "\t\t\t# Convert the value of the 'sex' attribute to a NumPy array if it is not already\n",
    "\t\t\tsex_array = np.array(x_control[attr])\n",
    "\t\t\tsex_binary = (sex_array == 'Female').astype(int)\n",
    "\t\t\tbinary_encoded_data[attr] = sex_binary\n",
    "\tx_control = binary_encoded_data\n",
    "\n",
    "\t\"\"\"permute the date randomly\"\"\"\n",
    "\tperm = list(range(0,X.shape[0]))\n",
    "\tshuffle(perm)\n",
    "\tX = X[perm]\n",
    "\ty = y[perm]\n",
    "\tfor k in x_control.keys():\n",
    "\t\tx_control[k] = x_control[k][perm]\n",
    "\n",
    "\n",
    "\tX = ut.add_intercept(X)\n",
    "\tprint(\"y\",y)    \n",
    "\n",
    "\tfeature_names = [\"intercept\"] + feature_names\n",
    "\tassert(len(feature_names) == X.shape[1])\n",
    "\tprint (\"Features we will be using for classification are:\", feature_names, \"\\n\")\n",
    "\n",
    "\n",
    "\treturn X, y, x_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b6ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_adult_data(load_data_size=None):\n",
    "\n",
    "    \"\"\"\n",
    "        if load_data_size is set to None (or if no argument is provided), then we load and return the whole data\n",
    "        if it is a number, say 10000, then we will return randomly selected 10K examples\n",
    "    \"\"\"\n",
    "\n",
    "    attrs = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country'] # all attributes\n",
    "    int_attrs = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week'] # attributes with integer values -- the rest are categorical\n",
    "    sensitive_attrs = ['sex','race'] # the fairness constraints will be used for this feature\n",
    "    attrs_to_ignore = ['sex', 'race' ,'fnlwgt'] # sex and race are sensitive feature so we will not use them in classification, we will not consider fnlwght for classification since its computed externally and it highly predictive for the class (for details, see documentation of the adult data)\n",
    "    attrs_for_classification = set(attrs) - set(attrs_to_ignore)\n",
    "\n",
    "    # adult data comes in two different files, one for training and one for testing, however, we will combine data from both the files\n",
    "    data_files = [\"adult.data\", \"adult.test\"]\n",
    "\n",
    "\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    x_control = {}\n",
    "\n",
    "    attrs_to_vals = {} # will store the values for each attribute for all users\n",
    "    for k in attrs:\n",
    "        if k in sensitive_attrs:\n",
    "            x_control[k] = []\n",
    "        elif k in attrs_to_ignore:\n",
    "            pass\n",
    "        else:\n",
    "            attrs_to_vals[k] = []\n",
    "\n",
    "    for f in data_files:\n",
    "       # check_data_file(f)\n",
    "\n",
    "        for line in open(f):\n",
    "            line = line.strip()\n",
    "            if line == \"\": continue # skip empty lines\n",
    "            line = line.split(\", \")\n",
    "            if len(line) != 15 or \"?\" in line: # if a line has missing attributes, ignore it\n",
    "                continue\n",
    "\n",
    "            class_label = line[-1]\n",
    "            if class_label in [\"<=50K.\", \"<=50K\"]:\n",
    "                class_label = -1\n",
    "            elif class_label in [\">50K.\", \">50K\"]:\n",
    "                class_label = +1\n",
    "            else:\n",
    "                raise Exception(\"Invalid class label value\")\n",
    "\n",
    "            y.append(class_label)\n",
    "\n",
    "\n",
    "            for i in range(0,len(line)-1):\n",
    "                attr_name = attrs[i]\n",
    "                attr_val = line[i]\n",
    "                # reducing dimensionality of some very sparse features\n",
    "                if attr_name == \"native_country\":\n",
    "                    if attr_val!=\"United-States\":\n",
    "                        attr_val = \"Non-United-Stated\"\n",
    "                elif attr_name == \"education\":\n",
    "                    if attr_val in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "                        attr_val = \"prim-middle-school\"\n",
    "                    elif attr_val in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "                        attr_val = \"high-school\"\n",
    "\n",
    "                if attr_name in sensitive_attrs:\n",
    "                    x_control[attr_name].append(attr_val)\n",
    "                elif attr_name in attrs_to_ignore:\n",
    "                    pass\n",
    "                else:\n",
    "                    attrs_to_vals[attr_name].append(attr_val)\n",
    "\n",
    "    def convert_attrs_to_ints(d): # discretize the string attributes\n",
    "        for attr_name, attr_vals in d.items():\n",
    "            if attr_name in int_attrs: continue\n",
    "            uniq_vals = sorted(list(set(attr_vals))) # get unique values\n",
    "\n",
    "            # compute integer codes for the unique values\n",
    "            val_dict = {}\n",
    "            for i in range(0,len(uniq_vals)):\n",
    "                val_dict[uniq_vals[i]] = i\n",
    "\n",
    "            # replace the values with their integer encoding\n",
    "            for i in range(0,len(attr_vals)):\n",
    "                attr_vals[i] = val_dict[attr_vals[i]]\n",
    "            d[attr_name] = attr_vals\n",
    "\n",
    "    \n",
    "    # convert the discrete values to their integer representations\n",
    "    #convert_attrs_to_ints(x_control) change the code because we want binary data for race too.\n",
    "    convert_attrs_to_ints(attrs_to_vals)\n",
    "    binary_encoded_data = {}\n",
    "\n",
    "    # Iterate through the keys (sensitive attributes) in the x_control dictionary\n",
    "    for attr in x_control:\n",
    "        # Perform binary encoding for each attribute separately\n",
    "\n",
    "        # For 'race' attribute:\n",
    "        if attr == 'race':\n",
    "            # Convert the value of the 'race' attribute to a NumPy array if it is not already\n",
    "            race_array = np.array(x_control[attr])\n",
    "            race_binary = (race_array == 'White').astype(int)\n",
    "            binary_encoded_data[attr] = race_binary\n",
    "\n",
    "        # For 'sex' attribute:\n",
    "        elif attr == 'sex':\n",
    "            # Convert the value of the 'sex' attribute to a NumPy array if it is not already\n",
    "            sex_array = np.array(x_control[attr])\n",
    "            sex_binary = (sex_array == 'Male').astype(int)\n",
    "            binary_encoded_data[attr] = sex_binary\n",
    "    x_control = binary_encoded_data\n",
    "\n",
    "    # if the integer vals are not binary, we need to get one-hot encoding for them\n",
    "    for attr_name in attrs_for_classification:\n",
    "        attr_vals = attrs_to_vals[attr_name]\n",
    "        if attr_name in int_attrs or attr_name == \"native_country\": # the way we encoded native country, its binary now so no need to apply one hot encoding on it\n",
    "            X.append(attr_vals)\n",
    "\n",
    "        else:            \n",
    "            attr_vals, index_dict = ut.get_one_hot_encoding(attr_vals)\n",
    "            for inner_col in attr_vals.T:                \n",
    "                X.append(inner_col) \n",
    "\n",
    "\n",
    "    # convert to numpy arrays for easy handline\n",
    "    X = np.array(X, dtype=float).T\n",
    "    y = np.array(y, dtype = float)\n",
    "    for k, v in x_control.items(): x_control[k] = np.array(v, dtype=float)\n",
    "        \n",
    "    # shuffle the data\n",
    "    perm = list(range(len(y))) # shuffle the data before creating each fold\n",
    "    shuffle(perm)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    for k in x_control.keys():\n",
    "        x_control[k] = x_control[k][perm]\n",
    "\n",
    "    # see if we need to subsample the data\n",
    "    if load_data_size is not None:\n",
    "        print (\"Loading only %d examples from the data\" % load_data_size)\n",
    "        X = X[:load_data_size]\n",
    "        y = y[:load_data_size]\n",
    "        for k in x_control.keys():\n",
    "            x_control[k] = x_control[k][:load_data_size]\n",
    "    \n",
    "    return X, y, x_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b44538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p_rule(x_control, class_labels):\n",
    "    \"\"\"Compute the p-rule based on Doctrine of disparate impact\"\"\"\n",
    "    \n",
    "    non_prot_all = sum(x_control == 1.0)  # non-protected group\n",
    "    prot_all = sum(x_control == 0.0)  # protected group\n",
    "    non_prot_pos = sum(class_labels[x_control == 1.0] == 1.0)  # non_protected in positive class\n",
    "    prot_pos = sum(class_labels[x_control == 0.0] == 1.0)  # protected in positive class\n",
    "    frac_non_prot_pos = float(non_prot_pos) / float(non_prot_all)\n",
    "    frac_prot_pos = float(prot_pos) / float(prot_all)\n",
    "    #p_rule = (frac_prot_pos / frac_non_prot_pos) * 100.0\n",
    "    p_rule = (min( (frac_non_prot_pos / frac_prot_pos), (frac_prot_pos / frac_non_prot_pos) )) * 100.0\n",
    "    print()\n",
    "    print(\"non_prot_pos\", non_prot_pos)\n",
    "    print(\"prot_pos\", prot_pos)\n",
    "    print(\"frac_non_prot_pos\", frac_non_prot_pos)\n",
    "    print(\"frac_prot_pos\", frac_prot_pos)\n",
    "    print(\"Total data points: %d\" % len(x_control))\n",
    "    print(\"# non-protected examples: %d\" % non_prot_all)\n",
    "    print(\"# protected examples: %d\" % prot_all)\n",
    "    print(\n",
    "        \"Non-protected in positive class: %d (%0.0f%%)\"\n",
    "        % (non_prot_pos, non_prot_pos * 100.0 / non_prot_all)\n",
    "    )\n",
    "    print(\n",
    "        \"Protected in positive class: %d (%0.0f%%)\"\n",
    "        % (prot_pos, prot_pos * 100.0 / prot_all)\n",
    "    )\n",
    "    print(\"P-rule is: %0.0f%%\" % p_rule)\n",
    "    return p_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778281ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_covariance_sensitive_attrs(model, x_arr, y_arr_dist_boundary, x_control, sensitive_attrs):\n",
    "\n",
    "    \"\"\"\n",
    "    reutrns the covariance between sensitive features and distance from decision boundary\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "    arr = y_arr_dist_boundary # simplt the output labels\n",
    "    \n",
    "    sensitive_attrs_to_cov_original = {}\n",
    "    for attr in sensitive_attrs:\n",
    "\n",
    "        attr_arr = x_control[attr]\n",
    "        #bin_attr = check_binary(attr_arr) # check if the attribute is binary (0/1), or has more than 2 vals\n",
    "        #if bin_attr == False: # if its a non-binary sensitive feature, then perform one-hot-encoding\n",
    "           # attr_arr_transformed, index_dict = get_one_hot_encoding(attr_arr)\n",
    "\n",
    "        thresh = 0\n",
    "        cov = thresh - test_sensitive_attr_constraint_cov(None, x_arr, arr, np.array(attr_arr), thresh, False)\n",
    "        sensitive_attrs_to_cov_original[attr] = cov\n",
    "       \n",
    "            \n",
    "    return sensitive_attrs_to_cov_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0f64bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constraint_list_cov(x_train, y_train, x_control_train, sensitive_attrs, sensitive_attrs_to_cov_thresh):\n",
    "\n",
    "    \"\"\"\n",
    "    get the list of constraints to be fed to the minimizer\n",
    "    \"\"\"\n",
    "\n",
    "    constraints = []\n",
    "    for attr in sensitive_attrs:\n",
    "        attr_arr = x_control_train[\"race\"]\n",
    "        integer_elements = []\n",
    "        for k in attr_arr:\n",
    "            try:\n",
    "                k = int(k)\n",
    "            except (ValueError, TypeError):\n",
    "                print(f\"Error: Element '{k}' cannot be converted to an integer.\")\n",
    "                return np.array([])\n",
    "            integer_elements.append(k)\n",
    "        attr_arr_transformed= np.array(integer_elements)\n",
    "        thresh = sensitive_attrs_to_cov_thresh[attr]\n",
    "        c = ({'type': 'ineq', 'fun': test_sensitive_attr_constraint_cov, 'args':(x_train, y_train, attr_arr_transformed,thresh, False)})\n",
    "        constraints.append(c)\n",
    "    #print (\"constraints\",constraints)\n",
    "    return constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a03b3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sensitive_attr_constraint_cov(model, x_arr, y_arr_dist_boundary, x_control, thresh, verbose):\n",
    "\n",
    "    \"\"\"\n",
    "    The covariance is computed b/w the sensitive attr val and the distance from the boundary\n",
    "    If the model is None, we assume that the y_arr_dist_boundary contains the distace from the decision boundary\n",
    "    If the model is not None, we just compute a dot product or model and x_arr\n",
    "    this function will return -1 if the constraint specified by thresh parameter is not satifsified\n",
    "    otherwise it will reutrn +1\n",
    "    if the return value is >=0, then the constraint is satisfied\n",
    "    \"\"\"\n",
    "\n",
    "    assert(x_arr.shape[0] == x_control.shape[0])\n",
    "    if len(x_control.shape) > 1: # make sure we just have one column in the array\n",
    "        assert(x_control.shape[1] == 1)\n",
    "    \n",
    "    arr = []\n",
    "    if model is None:\n",
    "        arr = y_arr_dist_boundary # simply the output labels\n",
    "    else:\n",
    "        arr = np.dot(model, x_arr.T) # the product with the weight vector -- the sign of this is the output label\n",
    "    \n",
    "    arr = np.array(arr, dtype=np.float64)\n",
    "    #print (\"arr1\",arr)\n",
    "    #print (\"arr0\",arr0)\n",
    "    cov = np.dot(x_control - np.mean(x_control), arr ) / float(len(x_control))\n",
    "   \n",
    "    ans = thresh - abs(cov) # will be <0 if the covariance is greater than thresh -- that is, the condition is not satisfied\n",
    "    # ans = thresh - cov # will be <0 if the covariance is greater than thresh -- that is, the condition is not satisfied\n",
    "    #print (\"ans\",ans)\n",
    "    if verbose is True:\n",
    "        print (\"Covariance is\", cov)\n",
    "        print (\"Diff is:\", ans)\n",
    "        print ()\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef50459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, x_train, y_train, x_test, y_test, y_train_predicted, y_test_predicted):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    returns the train/test accuracy of the model\n",
    "    \"\"\"\n",
    "\n",
    "    y_test_predicted = np.sign(np.dot(x_test, model))\n",
    "    y_train_predicted = np.sign(np.dot(x_train, model))\n",
    "\n",
    "    def get_accuracy(y, Y_predicted):\n",
    "        correct_answers = (Y_predicted == y).astype(int) # will have 1 when the prediction and the actual label match\n",
    "        accuracy = float(sum(correct_answers)) / float(len(correct_answers))\n",
    "        return accuracy, sum(correct_answers)\n",
    "\n",
    "    train_score, correct_answers_train = get_accuracy(y_train, y_train_predicted)\n",
    "    test_score, correct_answers_test = get_accuracy(y_test, y_test_predicted)\n",
    "\n",
    "    return train_score, test_score, correct_answers_train, correct_answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b583225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations(model, x_test, y_predicted, x_control_test, sensitive_attrs):\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    returns the fraction in positive class for sensitive feature values\n",
    "    \"\"\"\n",
    " \n",
    "    y_predicted = np.array(y_predicted)\n",
    "    \n",
    "    out_dict = {}\n",
    "    for attr in sensitive_attrs:\n",
    "\n",
    "        attr_val = []\n",
    "        for v in x_control_test[attr]: attr_val.append(v)\n",
    "        assert(len(attr_val) == len(y_predicted))\n",
    "\n",
    "\n",
    "        total_per_val = defaultdict(int)\n",
    "        attr_to_class_labels_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        for i in range(0, len(y_predicted)):\n",
    "            val = attr_val[i]\n",
    "            label = y_predicted[i]\n",
    "\n",
    "            # val = attr_val_int_mapping_dict_reversed[val] # change values from intgers to actual names\n",
    "            total_per_val[val] += 1\n",
    "            attr_to_class_labels_dict[val][label] += 1\n",
    "\n",
    "        class_labels = set(y_predicted.tolist())\n",
    "\n",
    "        local_dict_1 = {}\n",
    "        for k1,v1 in attr_to_class_labels_dict.items():\n",
    "            total_this_val = total_per_val[k1]\n",
    "\n",
    "            local_dict_2 = {}\n",
    "            for k2 in class_labels: # the order should be the same for printing\n",
    "                v2 = v1[k2]\n",
    "\n",
    "                f = float(v2) * 100.0 / float(total_this_val)\n",
    "\n",
    "\n",
    "                local_dict_2[k2] = f\n",
    "            local_dict_1[k1] = local_dict_2\n",
    "        out_dict[attr] = local_dict_1\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b8387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_correlation_dict(correlation_dict_arr):\n",
    "    # make the structure for the correlation dict\n",
    "    correlation_dict_avg = {}\n",
    "    # print correlation_dict_arr\n",
    "    for k,v in correlation_dict_arr[0].items():\n",
    "        correlation_dict_avg[k] = {}\n",
    "        for feature_val, feature_dict in v.items():\n",
    "            correlation_dict_avg[k][feature_val] = {}\n",
    "            for class_label, frac_class in feature_dict.items():\n",
    "                correlation_dict_avg[k][feature_val][class_label] = []\n",
    "\n",
    "    # populate the correlation dict\n",
    "    for correlation_dict in correlation_dict_arr:\n",
    "        for k,v in correlation_dict.items():\n",
    "            for feature_val, feature_dict in v.items():\n",
    "                for class_label, frac_class in feature_dict.items():\n",
    "                    correlation_dict_avg[k][feature_val][class_label].append(frac_class)\n",
    "\n",
    "    # now take the averages\n",
    "    for k,v in correlation_dict_avg.items():\n",
    "        for feature_val, feature_dict in v.items():\n",
    "            for class_label, frac_class_arr in feature_dict.items():\n",
    "                correlation_dict_avg[k][feature_val][class_label] = np.mean(frac_class_arr)\n",
    "\n",
    "    return correlation_dict_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35e47878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_intercept(x):\n",
    "\n",
    "    \"\"\" Add intercept to the data before linear classification \"\"\"\n",
    "    m,n = x.shape\n",
    "    intercept = np.ones(m).reshape(m, 1) # the constant b\n",
    "    return np.concatenate((intercept, x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "efa1e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classifier_fairness_stats(acc_arr, correlation_dict_arr, cov_dict_arr, s_attr_name):\n",
    "    \n",
    "    correlation_dict = get_avg_correlation_dict(correlation_dict_arr)\n",
    "    non_prot_pos = correlation_dict[s_attr_name][1][1]\n",
    "    prot_pos = correlation_dict[s_attr_name][0][1]\n",
    "    p_rule = (min( (non_prot_pos / prot_pos), (prot_pos / non_prot_pos) )) * 100.0\n",
    "    print (\"Accuracy: %0.2f\" % (np.mean(acc_arr)) )\n",
    "    print (\"Protected/non-protected in +ve class: %0.0f%% / %0.0f%%\" % (prot_pos, non_prot_pos) )\n",
    "    print (\"P-rule achieved: %0.0f%%\" % (p_rule) )\n",
    "    print (\"Covariance between sensitive feature and decision from distance boundary : %0.3f\" % (np.mean([v[s_attr_name] for v in cov_dict_arr])))\n",
    "    print ()\n",
    "    return p_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "022c51b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_cross_validation_error(x_all, y_all, x_control_all, num_folds, loss_function, apply_fairness_constraints, sensitive_attrs, sensitive_attrs_to_cov_thresh_arr):\n",
    "    n_samples = len(y_all)\n",
    "    train_fold_size = 0.7  # the rest of 0.3 is for testing\n",
    "    max_iter = 10000 # maximum number of iterations for the minimization algorithm\n",
    "    train_folds = []\n",
    "    test_folds = []\n",
    "\n",
    "    # Split the data into folds for cross-validation\n",
    "    for i in range(num_folds):\n",
    "        perm = list(range(n_samples))\n",
    "        shuffle(perm)\n",
    "        x_all_perm = x_all[perm]\n",
    "        y_all_perm = y_all[perm]\n",
    "        x_control_all_perm = {k: np.array(x_control_all[k])[perm] for k in x_control_all.keys()}\n",
    "\n",
    "        x_all_train, y_all_train, x_control_all_train, x_all_test, y_all_test, x_control_all_test = split_into_train_test(x_all_perm, y_all_perm, x_control_all_perm, train_fold_size)\n",
    "\n",
    "        train_folds.append([x_all_train, y_all_train, x_control_all_train])\n",
    "        test_folds.append([x_all_test, y_all_test, x_control_all_test])\n",
    "\n",
    "    test_acc_arr = []\n",
    "    train_acc_arr = []\n",
    "    correlation_dict_test_arr = []\n",
    "    correlation_dict_train_arr = []\n",
    "    cov_dict_test_arr = []\n",
    "    cov_dict_train_arr = []\n",
    "    for fold_num in range(num_folds):\n",
    "        train_data = train_folds[fold_num]\n",
    "        test_data = test_folds[fold_num]\n",
    "        sensitive_attrs_to_cov_thresh = sensitive_attrs_to_cov_thresh_arr[fold_num]\n",
    "        #print ('sensitive_attrs_to_cov_thresh',sensitive_attrs_to_cov_thresh)\n",
    "        x_train, y_train, x_control_train = train_data\n",
    "        x_test, y_test, x_control_test = test_data\n",
    "        f_args=(x_train, y_train)\n",
    "        if apply_fairness_constraints == 0:\n",
    "            w = minimize(fun = loss_function,\n",
    "                 x0 = np.random.rand(x_train.shape[1],),       \n",
    "                 args = f_args, \n",
    "                 method = 'SLSQP',\n",
    "                 options = {\"maxiter\":max_iter},\n",
    "                 constraints = []\n",
    "                 )\n",
    "        else: \n",
    "            constraints = get_constraint_list_cov(x_train, y_train,x_control_train, sensitive_attrs, sensitive_attrs_to_cov_thresh)  \n",
    "            w = minimize(fun = loss_function,\n",
    "                 x0 = np.random.rand(x_train.shape[1],),       \n",
    "                 args = f_args, \n",
    "                 method = 'SLSQP',\n",
    "                 options = {\"maxiter\":max_iter},\n",
    "                 constraints = constraints\n",
    "                 )     \n",
    "        try:\n",
    "            assert(w.success == True)\n",
    "        except:\n",
    "            print (\"Optimization problem did not converge.. Check the solution returned by the optimizer.\")\n",
    "            print (\"Returned solution is:\")\n",
    "            print (w)             \n",
    "        train_score, test_score, correct_answers_train, correct_answers_test = check_accuracy(w.x, x_train, y_train, x_test, y_test, None, None)\n",
    "        distances_boundary_test = (np.dot(x_test, w.x)).tolist()\n",
    "        all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "        correlation_dict_test = get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "        cov_dict_test = print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "\n",
    "        distances_boundary_train = (np.dot(x_train, w.x)).tolist()\n",
    "        all_class_labels_assigned_train = np.sign(distances_boundary_train)\n",
    "        correlation_dict_train = get_correlations(None, None, all_class_labels_assigned_train, x_control_train, sensitive_attrs)\n",
    "        cov_dict_train = print_covariance_sensitive_attrs(None, x_train, distances_boundary_train, x_control_train, sensitive_attrs)\n",
    "\n",
    "        test_acc_arr.append(test_score)\n",
    "        train_acc_arr.append(train_score)\n",
    "        correlation_dict_test_arr.append(correlation_dict_test)\n",
    "        correlation_dict_train_arr.append(correlation_dict_train)\n",
    "        cov_dict_test_arr.append(cov_dict_test)\n",
    "        cov_dict_train_arr.append(cov_dict_train)\n",
    "                 \n",
    "\n",
    "    return test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b935a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_train_test(x_all, y_all, x_control_all, train_fold_size):\n",
    "\n",
    "    split_point = int(round(float(x_all.shape[0]) * train_fold_size))\n",
    "    x_all_train = x_all[:split_point]\n",
    "    x_all_test = x_all[split_point:]\n",
    "    y_all_train = y_all[:split_point]\n",
    "    y_all_test = y_all[split_point:]\n",
    "    x_control_all_train = {}\n",
    "    x_control_all_test = {}\n",
    "    for k in x_control_all.keys():\n",
    "        x_control_all_train[k] = x_control_all[k][:split_point]\n",
    "        x_control_all_test[k] = x_control_all[k][split_point:]\n",
    "\n",
    "    return x_all_train, y_all_train, x_control_all_train, x_all_test, y_all_test, x_control_all_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da9679d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cov_thresh_vs_acc_pos_ratio(x_all, y_all, x_control_all, num_folds, loss_function, sensitive_attrs):\n",
    "\n",
    "\n",
    "    # very the covariance threshold using a range of decreasing multiplicative factors and see the tradeoffs between accuracy and fairness\n",
    "    it = 0.05\n",
    "    cov_range = np.arange(1.0, 0.0-it, -it).tolist()\n",
    "    \n",
    "    positive_class_label = 1 # positive class is +1\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    positive_per_category = defaultdict(list) # for each category (male / female), the frac of positive\n",
    "\n",
    "    # first get the original values of covariance in the unconstrained classifier -- these original values are not needed for reverse constraint    \n",
    "    test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr = compute_cross_validation_error(x_all, y_all, x_control_all, num_folds, loss_function, 0, sensitive_attrs, [{} for i in range(0,num_folds)])\n",
    "\n",
    "    for c in cov_range:\n",
    "        print (\"LOG: testing for multiplicative factor: %0.2f\" % c)\n",
    "        sensitive_attrs_to_cov_original_arr_multiplied = []\n",
    "        for sensitive_attrs_to_cov_original in cov_dict_train_arr:\n",
    "            sensitive_attrs_to_cov_thresh = deepcopy(sensitive_attrs_to_cov_original)\n",
    "            for k in sensitive_attrs_to_cov_thresh.keys():\n",
    "                v = sensitive_attrs_to_cov_thresh[k]\n",
    "                if type(v) == type({}):\n",
    "                    for k1 in v.keys():\n",
    "                        v[k1] = v[k1] * c\n",
    "                else:\n",
    "                    sensitive_attrs_to_cov_thresh[k] = v * c\n",
    "            sensitive_attrs_to_cov_original_arr_multiplied.append(sensitive_attrs_to_cov_thresh)\n",
    "\n",
    "\n",
    "        test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr  = compute_cross_validation_error(x_all, y_all, x_control_all, num_folds, loss_function, 1, sensitive_attrs, sensitive_attrs_to_cov_original_arr_multiplied)\n",
    "        test_acc.append(np.mean(test_acc_arr))\n",
    "\n",
    "\n",
    "        correlation_dict_train = get_avg_correlation_dict(correlation_dict_train_arr)\n",
    "        correlation_dict_test = get_avg_correlation_dict(correlation_dict_test_arr)\n",
    "        \n",
    "        # just plot the correlations for the first sensitive attr, the plotting can be extended for the other values, but as a proof of concept, we will jsut show for one\n",
    "        s = sensitive_attrs[0]    \n",
    "        \n",
    "        for k,v in correlation_dict_test[s].items():\n",
    "            if v.get(positive_class_label) is None:\n",
    "                positive_per_category[k].append(0.0)\n",
    "            else:\n",
    "                positive_per_category[k].append(v[positive_class_label])\n",
    "    \n",
    "    positive_per_category = dict(positive_per_category)\n",
    "    \n",
    "    ratios = np.array(positive_per_category[1]) / np.array(positive_per_category[0])\n",
    "    reverse_ratios = np.array(positive_per_category[0]) / np.array(positive_per_category[1])\n",
    "    # Calculate the minimum ratio between ratios and reverse_ratios element-wise\n",
    "    p_rule_arr = np.minimum(ratios, reverse_ratios) * 100.0\n",
    "    \n",
    "\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    plt.plot(cov_range, positive_per_category[0], \"-o\" , color=\"green\", label = \"Protected\")\n",
    "    plt.plot(cov_range, positive_per_category[1], \"-o\", color=\"blue\", label = \"Non-protected\")\n",
    "    ax.set_xlim([min(cov_range), max(cov_range)])\n",
    "    plt.ylabel('Perc. in positive class')\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xlabel('Multiplicative covariance factor (c)')\n",
    "    ax.legend()\n",
    "\n",
    "    ax = plt.subplot(2,1,2)\n",
    "    plt.scatter(p_rule_arr, test_acc, color=\"red\")\n",
    "    ax.set_xlim([min(p_rule_arr), max(max(p_rule_arr), 100)])\n",
    "    plt.xlabel('P% rule')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a386a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _logistic_loss(w, X, y, return_arr=None):\n",
    "\t\"\"\"Computes the logistic loss.\n",
    "\n",
    "\tThis function is used from scikit-learn source code\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tw : ndarray, shape (n_features,) or (n_features + 1,)\n",
    "\t    Coefficient vector.\n",
    "\n",
    "\tX : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "\t    Training data.\n",
    "\n",
    "\ty : ndarray, shape (n_samples,)\n",
    "\t    Array of labels.\n",
    "\n",
    "\t\"\"\"\n",
    "\t\n",
    "\n",
    "\tyz = y * np.dot(X,w)\n",
    "\t# Logistic loss is the negative of the log of the logistic function.\n",
    "\tif return_arr == True:\n",
    "\t\tout = -(log_logistic(yz))\n",
    "\telse:\n",
    "\t\tout = -np.sum(log_logistic(yz))\n",
    "\treturn out\n",
    "\n",
    "def log_logistic(X):\n",
    "\n",
    "\t\"\"\" This function is used from scikit-learn source code. Source link below \"\"\"\n",
    "\n",
    "\t\"\"\"Compute the log of the logistic function, ``log(1 / (1 + e ** -x))``.\n",
    "\tThis implementation is numerically stable because it splits positive and\n",
    "\tnegative values::\n",
    "\t    -log(1 + exp(-x_i))     if x_i > 0\n",
    "\t    x_i - log(1 + exp(x_i)) if x_i <= 0\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tX: array-like, shape (M, N)\n",
    "\t    Argument to the logistic function\n",
    "\n",
    "\tReturns\n",
    "\t-------\n",
    "\tout: array, shape (M, N)\n",
    "\t    Log of the logistic function evaluated at every point in x\n",
    "\tNotes\n",
    "\t-----\n",
    "\tSource code at:\n",
    "\thttps://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/extmath.py\n",
    "\t-----\n",
    "\n",
    "\tSee the blog post describing this implementation:\n",
    "\thttp://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/\n",
    "\t\"\"\"\n",
    "\tif X.ndim > 1: raise Exception(\"Array of samples cannot be more than 1-D!\")\n",
    "\tout = np.empty_like(X) # same dimensions and data types\n",
    "\n",
    "\tidx = X>0\n",
    "\tout[idx] = -np.log(1.0 + np.exp(-X[idx]))\n",
    "\tout[~idx] = X[~idx] - np.log(1.0 + np.exp(X[~idx]))\n",
    "\treturn out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9f78233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of people recidivating within two years\n",
      "-1    2795\n",
      " 1    2483\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "y [-1 -1  1 ... -1  1 -1]\n",
      "Features we will be using for classification are: ['intercept', 'age_cat_25 - 45', 'age_cat_Greater than 45', 'age_cat_Less than 25', 'priors_count', 'c_charge_degree'] \n",
      "\n",
      "x_control {'sex': array([1, 0, 1, ..., 0, 0, 0]), 'race': array([0, 0, 1, ..., 0, 1, 0])}\n",
      "\n",
      "non_prot_pos 822\n",
      "prot_pos 1661\n",
      "frac_non_prot_pos 0.3908701854493581\n",
      "frac_prot_pos 0.5231496062992126\n",
      "Total data points: 5278\n",
      "# non-protected examples: 2103\n",
      "# protected examples: 3175\n",
      "Non-protected in positive class: 822 (39%)\n",
      "Protected in positive class: 1661 (52%)\n",
      "P-rule is: 75%\n",
      "\n",
      "== (Original) classifier ==\n",
      "Accuracy: 0.66\n",
      "Protected/non-protected in +ve class: 53% / 28%\n",
      "P-rule achieved: 53%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.122\n",
      "\n",
      "\n",
      "== Constrained (fair) classifier ==\n",
      "Accuracy: 0.49\n",
      "Protected/non-protected in +ve class: 23% / 31%\n",
      "P-rule achieved: 74%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.002\n",
      "\n",
      "LOG: testing for multiplicative factor: 1.00\n",
      "LOG: testing for multiplicative factor: 0.95\n",
      "LOG: testing for multiplicative factor: 0.90\n",
      "LOG: testing for multiplicative factor: 0.85\n",
      "LOG: testing for multiplicative factor: 0.80\n",
      "LOG: testing for multiplicative factor: 0.75\n",
      "LOG: testing for multiplicative factor: 0.70\n",
      "LOG: testing for multiplicative factor: 0.65\n",
      "LOG: testing for multiplicative factor: 0.60\n",
      "LOG: testing for multiplicative factor: 0.55\n",
      "LOG: testing for multiplicative factor: 0.50\n",
      "LOG: testing for multiplicative factor: 0.45\n",
      "LOG: testing for multiplicative factor: 0.40\n",
      "LOG: testing for multiplicative factor: 0.35\n",
      "LOG: testing for multiplicative factor: 0.30\n",
      "LOG: testing for multiplicative factor: 0.25\n",
      "LOG: testing for multiplicative factor: 0.20\n",
      "LOG: testing for multiplicative factor: 0.15\n",
      "LOG: testing for multiplicative factor: 0.10\n",
      "LOG: testing for multiplicative factor: 0.05\n",
      "LOG: testing for multiplicative factor: -0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_FOLDS = 10 # we will show 10-fold cross validation accuracy as a performance measure\n",
    "\n",
    "def test_data():\n",
    "\n",
    "    \"\"\" Load the adult data \"\"\"\n",
    "    X, y, x_control = load_compas_data() # set the argument to none, or no arguments if you want to test with the whole data -- we are subsampling for performance speedup\n",
    "    print (\"x_control\",x_control)\n",
    "    compute_p_rule(x_control[\"race\"], y) # compute the p-rule in the original data\n",
    "\n",
    "    loss_function = _logistic_loss\n",
    "    X = add_intercept(X) # add intercept to X before applying the linear classifier\n",
    "    print()\n",
    "    print (\"== (Original) classifier ==\")\n",
    "    cov_factor = 0\n",
    "    test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr = compute_cross_validation_error(X, y, x_control, NUM_FOLDS, loss_function, 0, ['race'], [{'race':cov_factor} for i in range(0,NUM_FOLDS)])\t\t\n",
    "    print_classifier_fairness_stats(test_acc_arr, correlation_dict_test_arr, cov_dict_test_arr, 'race')\n",
    "    print()\n",
    "    print (\"== Constrained (fair) classifier ==\")\n",
    "    cov_factor = 0\n",
    "    test_acc_arr, train_acc_arr, correlation_dict_test_arr, correlation_dict_train_arr, cov_dict_test_arr, cov_dict_train_arr = compute_cross_validation_error(X, y, x_control, NUM_FOLDS, loss_function, 1, ['race'], [{'race':cov_factor} for i in range(0,NUM_FOLDS)])\t\t\n",
    "    \n",
    "    print_classifier_fairness_stats(test_acc_arr, correlation_dict_test_arr, cov_dict_test_arr, 'race')\n",
    "    \n",
    "    \"\"\" Now plot a tradeoff between the fairness and accuracy \"\"\"\n",
    "    plot_cov_thresh_vs_acc_pos_ratio(X, y, x_control, NUM_FOLDS, loss_function, ['race'])\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    test_data()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
